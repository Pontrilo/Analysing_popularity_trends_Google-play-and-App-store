{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App Store and Google Play profitable App profiling\n",
    "\n",
    "Working for a company that builds Android and iOS mobile apps that are available on the Google Play and App store, for this project we are going to be comparing App profiles. The solutions will help developers make better decisions on how to design and update their apps.\n",
    "\n",
    "The apps designed by the company are all free to download and install so all revenue comes from Ads. As revenue for adverts comes from in app views of the advert we are going to be comparing frequency data so developers can identify which apps are more attractive to their customer base.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the data\n",
    "\n",
    "As of 2018 there was roughly around 2 million Apps in both Google Play and the App Store.\n",
    "\n",
    "Collecting data on 4+ million apps will take a long time and costly to attain the data in the first place. To avoid suffering a large personal cost and in the respect of time we are going to locate some relevant sample data for free.\n",
    "\n",
    "Fortunately there is two data sets already fit for this purpose:\n",
    "\n",
    "- [Google Play data](https://www.kaggle.com/lava18/google-play-store-apps/home) containing data about approximately ten thousand Android apps from Google Play\n",
    "- [App Store data](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/home) containing data about approximately seven thousand iOS apps from the App Store\n",
    "\n",
    "First off we have to open the two datasets and read them in.\n",
    "*(Note: we are working with csv's here so import the reader from the csv module. We also set two variables for the data content and header)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'googleplaystore.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-937a11f556d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Google Play data imported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mopen_google_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"googleplaystore.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mread_google_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen_google_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgoogle_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_google_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'googleplaystore.csv'"
     ]
    }
   ],
   "source": [
    "# Import the reader from the csv module\n",
    "from csv import reader\n",
    "\n",
    "# Google Play data imported\n",
    "open_google_file = open(\"googleplaystore.csv\")\n",
    "read_google_file = reader(open_google_file)\n",
    "google_data = list(read_google_file)\n",
    "google_data_header = google_data[0]\n",
    "google_data_content = google_data[1:]\n",
    "\n",
    "# App Store data imported\n",
    "open_apple_file = open(\"AppleStore.csv\")\n",
    "read_apple_file = reader(open_apple_file)\n",
    "apple_data = list(read_apple_file)\n",
    "apple_data_header = apple_data[0]\n",
    "apple_data_content = apple_data[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the two datasets we will create a function called `explore_data()` that will allow us to easily read the rows and columns of a data set. An optional variable will be added to allow the calculation of the number of rows and columns in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, indexStart, indexEnd, count_rows_columns=False):\n",
    "    rows = dataset[indexStart:indexEnd]\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "        # insert blank line after each row list\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if count_rows_columns is True:\n",
    "        print(\"Number of rows: \", len(dataset))\n",
    "        print(\"Number of columns: \", len(dataset[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test the test the Google data and print the first 3 rows. we will also initialise the counting section of the function and have a look at the header of row of the Google data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show the Google header column\n",
    "\n",
    "print(google_data_header)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first look, for frequency testing we will most likely need the columns *\"App\", \"Category\", \"Reviews\", \"Installs\", \"Type\", \"Price\" and \"Genres\"*. Now we know the header works let's test our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the function with google data\n",
    "\n",
    "explore_data(google_data_content, 0, 3, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Success! The function works and it seems the Google data has **13 columns** and **10841 rows**. Let's do the same with the Apple data and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the header data for Apple\n",
    "\n",
    "print(apple_data_header)\n",
    "print(\"\\n\")\n",
    "explore_data(apple_data_content, 0, 3, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "So this data set contains 7197 iOS apps. Similar to Google we will detail the columns that might of most use; *\"track_name\", \"currency\", \"price\", \"rating_count_tot\", \"rating_count_ver\", and 'prime_genre'.*\n",
    "\n",
    "If you are unsure on what any of the column headers show there are descriptions that can be found in the documention:\n",
    "\n",
    "[Documentation](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/home)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing incorrect rows\n",
    "\n",
    "The Google data set has a dedicated discussion section, and we can see that one of the discussions outlines an error for row 10472.\n",
    "\n",
    "Upon review it seems there seems to be a missing column for this row. To confirm this and also check there are no other rows that are also  exhibiting the same problem we are going to search the Google data for any rows that are not the same length of the header and print the index of that row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We are going to use our data set without the header so we\n",
    "need to bring in the header row as a variable, this is just\n",
    "a personal preference\n",
    "\"\"\" \n",
    "\n",
    "for row in google_data_content:\n",
    "    row_length = google_data_header\n",
    "    if len(row) != len(row_length):\n",
    "        print(row)\n",
    "        print(\"\\n\")\n",
    "        print(google_data_content.index(row))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It seems there is only one row that exhibits this problem and its on row 10472 of the data set for the app \"Life Made WI-Fi Touchscreen Photo Fram\". *Remember if we include the header row it would be one index more at 10473*\n",
    "\n",
    "To check what the problem is lets print the header list alongside the troublesome row and see if anything stands out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(google_data_header)\n",
    "print(\"\\n\")\n",
    "print(google_data_content[10472])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the third element of both rows we can see that the Life Made app seems to have a rating of 19. This is clearly a mistake as Google Play apps have a max rating of 5. We are therefore going to delete the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We simply delete the row to remove the app\n",
    "\n",
    "del google_data_content[10472]\n",
    "\n",
    "# If we now print the row again you can see it has changed\n",
    "\n",
    "print(google_data_content[10472])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicate entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying duplicate entries\n",
    "\n",
    "If we continue to explore the discussions for the Google data at; [Discussions](https://www.kaggle.com/lava18/google-play-store-apps/discussion)\n",
    "\n",
    "You will see on a couple of occurances there is mention of duplicate entries for certains apps. We therefore need to identify this apps, work out which entries to keep and delete the extra.\n",
    "\n",
    "First things first we can identify duplicate entries by tracking down rows that have the same app name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set two lists for duplicate entries and \n",
    "unique entries to be saved to\n",
    "\"\"\"\n",
    "\n",
    "duplicate_entries = []\n",
    "unique_entries = []\n",
    "\n",
    "for row in google_data_content:\n",
    "    app_name = row[0]\n",
    "    if app_name in unique_entries:\n",
    "        duplicate_entries.append(app_name)\n",
    "    else:\n",
    "        unique_entries.append(app_name)\n",
    "\n",
    "print(\"Unique entries: \", len(unique_entries))\n",
    "print(\"\\n\")\n",
    "print(\"Duplicate entries: \", len(duplicate_entries))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Creating total_entries is just for tidyness\n",
    "total_entries = len(duplicate_entries) + len(unique_entries)\n",
    "\n",
    "# A quick sense check to make sure we checked every row\n",
    "if total_entries == len(google_data_content):\n",
    "    print(\"All rows have been assigned to duplicate or unique\")\n",
    "else:\n",
    "    print(\"Mistakes were made\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we have a list of all the duplicate app names we can check a few to test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first 20 duplicate entries\n",
    "\n",
    "print(duplicate_entries[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using a small piece of code we can create a function that will take an index for the `duplicate_entries` list and return us all the rows with that app_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dup_check(dup_index):\n",
    "    for row in google_data_content:\n",
    "        dup_name = row[0]\n",
    "        if dup_name == duplicate_entries[dup_index]:\n",
    "            print(row)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are looking at Google data lets look at some duplicates for Google apps and see if we can see what's going on. from our first 20 lets look at the following:\n",
    "\n",
    "- \"Google My Buiness\" = index(2)\n",
    "- \"Google Ads\" = index(7)\n",
    "- \"Google Analytics\" = index(18)\n",
    "\n",
    "As we built a function we can just run it three times and see what we get\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_check(2)\n",
    "dup_check(7)\n",
    "dup_check(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look through the above list of lists we can see the only number that changes is the \"number of reviews\" in column 4 for the \"Google Ads\" app.\n",
    "\n",
    "We know we cannot keep multiple entries for the same app  and ideally we would not want to delete rows randomly. By noticing the change in column 4 it is safe to say that the duplicate rows with the highest reviews is the latest entry and therefore the app row that we are going to keep.\n",
    "\n",
    "In the next section we will look at how we might go about deleting the duplicate apps to meet this criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting apps based on criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two steps to deleting the duplicate rows:\n",
    "\n",
    "- Create a dictionary where each key is a unique app name, and the value is the highest number of reviews of that app\n",
    "- Use the dictionary to create a new data set, which will have only one entry per app (and we only select the apps with the highest number of reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this can get a bit loopy (literally in this case) it's best broken down into a series of steps:\n",
    "\n",
    "- Assign an empty dictionary\n",
    "- loop over the Google data looking at every row\n",
    "- Assign a variable for the app name and number of reviews\n",
    "- the logic then goes as follows:\n",
    "  - If the app name isn't in the dictionary add it and the corresponding number of reviews.\n",
    "  - If the app name is in the dictionary check if the new app entry has a higher review number than the value in the dictionary. If it does replace the app name dictionary key with the new number of reviews value\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_max = {}\n",
    "\n",
    "for row in google_data_content:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    \n",
    "    if name in reviews_max and reviews_max[name] < n_reviews:\n",
    "        reviews_max[name] = n_reviews\n",
    "        \n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from earlier on in our code the number of unique entries should be **9659**. As reviews_max should now contain a dictionary of unique values we can check that this equals the length of the list of unique values from earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Oringinal unique entries list: \", len(unique_entries))\n",
    "print(\"\\n\")\n",
    "print(\"length of reviews_max dictionary: \", len(reviews_max))\n",
    "print(\"\\n\")\n",
    "\n",
    "if len(reviews_max) == len(unique_entries):\n",
    "    print(\"Excellent, they match!\")\n",
    "else:\n",
    "    print(\"Mistakes were made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We now have a nice dictionary full of the unique app names and their highest rating. Now for the second part, stripping the original data of all entries that do not exhibit these two variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step two:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To strip the data from our main source we will undergo another series of steps when again is best explained in simple English:\n",
    "\n",
    "- We start by initializing two empty lists, google_data_clean and already_added.\n",
    "- We loop through the Google data set, and for every iteration:\n",
    "  - We set the name of the app and the number of reviews to a variable.\n",
    "  - We then add the current row (app) to the google_data_clean list, and the app name (name) to the already_cleaned list if:\n",
    "    - The number of reviews of the current app matches the number of reviews of that app as described in the reviews_max dictionary; and\n",
    "    - The name of the app is not already in the already_added list. We need to add this extra condition to account for those cases where the highest number of reviews of a duplicate app is the same for more than one entry (consider the other Google apps we looked at earlier where the number of reviews was the same for multiple entries). If we just check for reviews_max[name] == n_reviews, we'll still end up with duplicate entries for some apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will be our new cleansed list\n",
    "google_data_clean = []\n",
    "# List for dealing with identical rows\n",
    "already_added = []\n",
    "\n",
    "for row in google_data_content:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    if (reviews_max[name] == n_reviews) and (name not in \n",
    "                                             already_added):\n",
    "        google_data_clean.append(row)\n",
    "        already_added.append(name)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `explore_data` function we created earlier to count the number of rows in our new data set to make sure it is definately **9659**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explore_data(google_data_clean, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! That's the correct number of rows.\n",
    "\n",
    "After going through the data a bit more as we are working for an English based company the next stage is to remove foreign apps. We will explore that now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing foreign apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying non ASCII characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As some apps are not written using the English language language and we are not interested in keeping these kind of apps, we'll remove them. One way to go about this is to remove each app whose name contains a symbol that is not commonly used in English text ‚Äî English text usually includes letters from the English alphabet, numbers composed of digits from 0 to 9, punctuation marks (., !, ?, ;, etc.), and other symbols (+, *, /, etc.).\n",
    "\n",
    "All these characters that are specific to English texts are encoded using the ASCII standard. Each ASCII character has a corresponding number between 0 and 127 associated with it, and we can take advantage of that to build a function that checks an app name and tells us whether it contains non-ASCII characters.\n",
    "\n",
    "So a simple initial test we can do is elimate anything outside of the 0 - 127 range. Below we have created a function to test any app in any dataset based on its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_index_check(dataset, app_index):\n",
    "    app = dataset[app_index]\n",
    "    app_name = str(app[0])\n",
    "    print(app_name)\n",
    "    for character in app_name:\n",
    "        if ord(character) > 127:\n",
    "            return False\n",
    "    return True\n",
    "            \n",
    "            \n",
    "english_index_check(google_data_clean, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see for the app in index position 256 of our Google data there is non English text and therefore the funtion returns a False. We can check another to prove it works for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_index_check(google_data_clean, 258)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for plain English text we get a True as expected. Unfortunately this method creates a problem. Some apps use symbols, emojis and characters that fall outside of the ASCII range. Because of this, we'll remove useful apps if we use the function in its current form. As example can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_index_check(google_data_clean, 257)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The app is clearly English text but the use of the music symbols at the end returns a False. We therefore need to find a way around this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is rarely apps where there is lots of use of emojis and symbols a potential solution is to only label an app as non english when it has more than three characters that fall outside of the standard ASCII range. We can simply edit our previous function to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_index_check(dataset, app_index):\n",
    "    app = dataset[app_index]\n",
    "    app_name = str(app[0])\n",
    "    print(app_name)\n",
    "    non_character = 0\n",
    "    for character in app_name:\n",
    "        if ord(character) > 127:\n",
    "            non_character += 1\n",
    "            \n",
    "    if non_character > 3:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "    \n",
    "english_index_check(google_data_clean, 257)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is definately the case that this new system will let some non English apps through, but it will also now let a larger proportion of English apps through as well. You can see this in the example above as the the music symbols no longer identify the app as non English.\n",
    "\n",
    "Now we have our system we need to edit the function to be able to take in an app  name as a string instead of the index of the app and we can loop over both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_string_check(app_name):\n",
    "    count_non_ascii = 0\n",
    "    \n",
    "    for letter in app_name:\n",
    "        if ord(letter) > 127:\n",
    "            count_non_ascii += 1\n",
    "    \n",
    "    if count_non_ascii > 3:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a quick check to make sure it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(english_string_check(\"Docs To Go‚Ñ¢ Free Office Suite\"))\n",
    "print(english_string_check(\"Instachat üòú\"))\n",
    "print(english_string_check(\"Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These answers are as expected so let's run this for everything in our cleaned Google data and Apple data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_english = []\n",
    "apple_english = []\n",
    "\n",
    "for app in google_data_clean:\n",
    "    app_name = app[0]\n",
    "    if english_string_check(app_name) is True: \n",
    "        # 'is True' added for personal preference. It is not required\n",
    "        google_english.append(app)\n",
    "        \n",
    "for ios_app in apple_data_content:\n",
    "    # Remember the Apple data's first column was ID not the app name\n",
    "    ios_app_name = ios_app[1]\n",
    "    if english_string_check(ios_app_name) is True:\n",
    "        apple_english.append(ios_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can use the `explore_data` function to check these the english app checks worked as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(google_english, 0, 3, True)\n",
    "print('\\n')\n",
    "explore_data(apple_english, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A the number of apps has reduced and the first few columns show no obvious issues for this level of study we can consider this a success and move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing non free apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned at the beginning of this document we are only interested in apps that are free to both download and install. So far we have removed:\n",
    "\n",
    "- Incorrect data\n",
    "- Duplicate entries\n",
    "- Non enlgish apps\n",
    "\n",
    "Removing the non free apps from our data will be the last stage before we get stuck into some analysis.\n",
    "\n",
    "Luckily we have a price element for both datasets we can easily access. Using a similar layout for the previous stage we can easily filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_cleaned = []\n",
    "apple_cleaned = []\n",
    "\n",
    "for app in google_english:\n",
    "    price = app[7]\n",
    "    if price == \"0\":\n",
    "        google_cleaned.append(app)\n",
    "        \n",
    "for ios_app in apple_english:\n",
    "    cost = ios_app[4]\n",
    "    if cost == \"0.0\":  # Remember Apple data price is stored as a float\n",
    "        apple_cleaned.append(ios_app)\n",
    "\n",
    "# Explore the datasets one final time        \n",
    "explore_data(google_cleaned, 0, 3, True)\n",
    "print('\\n')\n",
    "explore_data(apple_cleaned, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we are left with 8864 Google apps and 3222 Apple apps, which is plenty to do some analysis on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Common Apps by Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our revenue is based on ads and therefore the number of views that we get following download and installs of our apps. We are going to look at the most popular types of apps that are more likely to attract future customers.\n",
    "\n",
    "The current stategy for app builds is as follows:\n",
    "\n",
    "- Build a minimal Android version of the app, and add it to Google Play.\n",
    "- If the app has a good response from users, we then develop it further.\n",
    "- If the app is profitable after six months, we also build an iOS version of the app and add it to the App Store.\n",
    "\n",
    "As our final product will be released on both android and ios systems we need to analyse app profiles from both sets of data to make sure the information we learn about one platform stays true on the other.\n",
    "\n",
    "We are going to start by looking at the most common genres for apps in the App store and Google Play. Using the methods we developed earlier we are going to first build a frequency table for the prime_genre column of the App Store data set, and the Genres and Category columns of the Google Play data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency table function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to generate the frequency tables for whatever column we wish to look at. It displays the frequencies as a percentage for the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(data, index):\n",
    "    frequency_table = {}\n",
    "    percentage_table = {}\n",
    "    total = 0\n",
    "    \n",
    "    for row in data:\n",
    "        total += 1\n",
    "        item = row[index]\n",
    "        \n",
    "        if item in frequency_table:\n",
    "            frequency_table[item] += 1\n",
    "        else:\n",
    "            frequency_table[item] = 1\n",
    "        \n",
    "    for key in frequency_table:\n",
    "        percentage = (frequency_table[key] / total) * 100\n",
    "        percentage_table[key] = percentage\n",
    "    \n",
    "    return percentage_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sorting function takes the percentages for each element of each column discovered in the frequency function and sorts them from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_table(data, index):\n",
    "    percent_table = freq_table(data, index)\n",
    "    display_list = []\n",
    "    \n",
    "    for key in percent_table:\n",
    "        key_val_tuple = (percent_table[key], key)\n",
    "        display_list.append(key_val_tuple)\n",
    "    \n",
    "    table_sorted = sorted(display_list, reverse=True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], \":\", entry[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the both functions we start by looking at the prime_genre column from the App Store dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apple_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-09f2a505df05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mordered_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapple_cleaned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'apple_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "ordered_table(apple_cleaned, -5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data we can see that from the filtered dataset showing free and English apps that over half are games (~58%). The other two highest are entertainment and photo/video apps. The rest of the genres make up less than 4% for each respective genre.\n",
    "\n",
    "From this it is clear that the vast amount of apps on the App store are past time apps for fun. However we are only counting the number of apps at this point so the quantity of apps available may not represent the actual use of the apps.\n",
    "\n",
    "Let's now look at the Genres and Category columns of the Google Play data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_table(google_cleaned, 1)  # Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category column for Google Play tells us a very different story, there are not that many apps designed for fun, and it seems that a good number of apps are designed for practical purposes (family, tools, business, lifestyle, productivity, etc.).\n",
    "\n",
    "However, if we investigate this further, we can see that the family category (which accounts for almost 19% of the apps) means mostly games for kids.\n",
    "\n",
    "Even so, practical apps seem to have a better representation on Google Play compared to App Store. This picture is also confirmed by the frequency table we see for the Genres column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_table(google_cleaned, -4)  # Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual difference between the Genre and Category column isn't actually explained fully. One thing we can see is that the Genre column has a lot more detail than the Category. We're only looking for the bigger picture at the moment, so we'll only work with the Category column moving forward.\n",
    "\n",
    "As we mentioned before the frequency may be deceptive however. So to try and get a better understanding of what apps are most successful by genre we will explore the number of users of the apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most popular apps by genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "One way to find out what genres are the most popular (have the most users) is to calculate the average number of installs for each app genre. For the Google Play data set, we can find this information in the Installs column, but for the App Store data set this information is missing. As a workaround, we'll take the total number of user ratings as a basic replacement, which we can find in the rating_count_tot column.\n",
    "\n",
    "Below, we calculate the average number of user ratings per app genre on the App Store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genre_table = freq_table(apple_cleaned, -5)\n",
    "\n",
    "for genre in genre_table:\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    \n",
    "    for row in apple_cleaned:\n",
    "        genre_app = row[-5]\n",
    "        if genre_app == genre:\n",
    "            user_rating = float(row[5])\n",
    "            total += user_rating\n",
    "            len_genre += 1\n",
    "    \n",
    "    avg_users = total / len_genre\n",
    "    print(genre, \":\", avg_users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average navigation is the highest so we will explore that first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for apps in apple_cleaned:\n",
    "    if apps[-5] == \"Navigation\":\n",
    "        print(apps[1], \":\", apps[5])  # name and ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see this is almost entirely dominated by Google and Waze so is not a good choice. Equally we can assume the same for other higher rankers that have a few dedicated pieces of software. A prime example of this is social networking which will be heavily skewed by the likes of Facebook, Twitter, Instagram etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for apps in apple_cleaned:\n",
    "    if apps[-5] == \"Music\":\n",
    "        print(apps[1], \":\", apps[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are looking at a primarily fun market as our basis for apps. The karaoke, music editing and streaming sections of music seem to have a reasonable average so there could be a market here for a new app which a high view rate for our ads. Also due to the length of time music editing or streaming takes to enjoy the content the exposure to the ads will be lengthy.\n",
    "\n",
    "The only downside to this is there is already a lot of similar ads for this market so a new strategy of how to make this work will need to be devised. Something along the lines of combining streaming recent music that can then be edited and sung along to after combines all the elements that have high user counts, but will also keep them entertained long enough for ad benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Google Play market, we actually have data about the number of installs, so we should be able to get a clearer picture about genre popularity. However, the install numbers don't seem precise enough ‚Äî we can see that most values are open-ended (100+, 1,000+, 5,000+, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_table(google_cleaned, 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform calculations on this data set we need the installs to be a number not a string so we will assume that the `\"+\"` is unimportant and the number represents the exact number of installs. We will also need to remove the comma so it can be recognised as a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_play = freq_table(google_cleaned, 1)  # category index is 1\n",
    "\n",
    "for category in google_play:\n",
    "    total = 0  # total will store the sum of the installs\n",
    "    len_category = 0  # this variable will store the number of specific apps per genre\n",
    "    for app in google_cleaned:\n",
    "        category_app = app[1]\n",
    "        if category_app == category:\n",
    "            n_installs = app[5]\n",
    "            n_installs = n_installs.replace(\"+\", \"\")\n",
    "            n_installs = n_installs.replace(\",\", \"\")\n",
    "            total += float(n_installs)\n",
    "            len_category += 1\n",
    "    avg_installs = total / len_category\n",
    "    print(category, \":\", avg_installs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On average, communication apps have the most installs: 38,456,119. We can assume this data is skewed as before by a few key players (WhatsApp, Facebook Messenger, Skype, Google Chrome, etc).. We can confirm this quickly to prove our point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in google_cleaned:\n",
    "    if app[1] == 'COMMUNICATION' and (app[5] == '1,000,000,000+'\n",
    "                                      or app[5] == '500,000,000+'\n",
    "                                      or app[5] == '100,000,000+'):\n",
    "        print(app[0], ':', app[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the big players are dominating. Again we can see this elsewhere in the other categories: the video players category, which is the runner-up with 24,727,872 installs. The market is dominated by apps like Youtube, Google Play Movies & TV, or MX Player. The pattern is repeated for social apps (where we have giants like Facebook, Instagram, Google+, etc.), photography apps (Google Photos and other popular photo editors), or productivity apps (Microsoft Word, Dropbox, Google Calendar, Evernote, etc.).\n",
    "\n",
    "Another area worth exploring in this case is books and references. With roughly 8 million views it has a high average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in google_cleaned:\n",
    "    if app[1] == 'BOOKS_AND_REFERENCE':\n",
    "        print(app[0], ':', app[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The book and reference genre includes a large number of apps: software for processing and reading ebooks, various collections of libraries, dictionaries, tutorials on programming or languages, etc. It seems there's still a small number of extremely popular apps that skew the average though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in google_cleaned:\n",
    "    if app[1] == 'BOOKS_AND_REFERENCE' and (app[5] == '1,000,000,000+'\n",
    "                                            or app[5] == '500,000,000+'\n",
    "                                            or app[5] == '100,000,000+'):\n",
    "        print(app[0], ':', app[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it looks like there are only a few very popular apps, so this market still shows potential. Let's try to get some app ideas based on the kind of apps that are somewhere in the middle in terms of popularity (between 1,000,000 and 100,000,000 downloads):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in google_cleaned:\n",
    "    if app[1] == 'BOOKS_AND_REFERENCE' and (app[5] == '1,000,000+'\n",
    "                                            or app[5] == '5,000,000+'\n",
    "                                            or app[5] == '10,000,000+'\n",
    "                                            or app[5] == '50,000,000+'):\n",
    "        print(app[0], ':', app[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This area seems to be dominated by software reading ebooks, as well as various collections of libraries and dictionaries, so it's probably not a good idea to build similar apps since there'll be some significant competition. Not to mention as they are free it will take a while to build a portfolio of books and/or gather enough information for a library resource.\n",
    "\n",
    "We also notice there are quite a few apps built around the book Quran in this set, we also know from the App Store the Bible has a large number of views, which suggests that building an app around a popular book can be profitable. It seems that taking a popular book (perhaps a more recent book) and turning it into an app could be profitable for both the Google Play and the App Store markets.\n",
    "\n",
    "However, it looks like the market is already full of recent books, so we need to add some special features besides the raw version of the book. This might include daily quotes from the book, an audio version of the book, quizzes on the book, a forum where people can discuss the book, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we analyzed data about the App Store and Google Play mobile apps with the goal of recommending an app profile that can be profitable for both markets.\n",
    "\n",
    "We concluded that taking a popular book (perhaps a more recent book) and turning it into an app could be profitable for both the Google Play and the App Store markets.\n",
    "\n",
    "We also identified a music app that has a new fun twist on the current examples of purely game or streaming apps would do well in the App Store market. There was no specific area to check this in Google Play without doing a lot more research, this could perhaps be something that is explored in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
